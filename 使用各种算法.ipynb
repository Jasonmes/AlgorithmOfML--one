{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0  k近邻算法 对鸢尾花数据进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_iris_demo():\n",
    "    '''\n",
    "    使用 k近邻算法 对鸢尾花数据进行预测\n",
    "    :return: None\n",
    "    '''\n",
    "\n",
    "    # 准备数据集\n",
    "    iris = load_iris()\n",
    "    #     特征值和目标值分清楚\n",
    "    #     切分训练集和测试集\n",
    "    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.8)\n",
    "    #     特征工程：\n",
    "    #         标准化\n",
    "    stand = StandardScaler()\n",
    "    x_train = stand.fit_transform(x_train)\n",
    "    x_test = stand.transform(x_test)\n",
    "    # 使用k近邻算法进行训练\n",
    "    #     实例化KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    #     训练 fit 训练集\n",
    "    knn.fit(x_train, y_train)\n",
    "    #     评估 score  测试集 n准确率\n",
    "    score = knn.score(x_test, y_test)\n",
    "    print('score', score)\n",
    "    #     预测 predict 测试集\n",
    "    y_predict = knn.predict(x_test)\n",
    "    print(y_predict == y_test)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1    使用 k近邻算法 对鸢尾花数据进行预测  增加交叉验证网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_iris_gridsearch_cv_demo():\n",
    "    '''\n",
    "    使用 k近邻算法 对鸢尾花数据进行预测\n",
    "    增加交叉验证网格搜索\n",
    "    :return: None\n",
    "    '''\n",
    "\n",
    "    # 准备数据集\n",
    "    iris = load_iris()\n",
    "    #     特征值和目标值分清楚\n",
    "    #     切分训练集和测试集\n",
    "    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.8)\n",
    "    #     特征工程：\n",
    "    #         标准化\n",
    "    stand = StandardScaler()\n",
    "    x_train = stand.fit_transform(x_train)\n",
    "    x_test = stand.transform(x_test)\n",
    "    # 使用k近邻算法进行训练\n",
    "    #     实例化KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    # 增加交叉验证网格搜索\n",
    "    # 构建参数字典\n",
    "    param_dict = {'n_neighbors':[1,3,5,7,9,11,13]}\n",
    "    gscv = GridSearchCV(knn, param_grid=param_dict, cv=3)\n",
    "    #     训练 fit 训练集\n",
    "    gscv.fit(x_train, y_train)\n",
    "    #     评估 score  测试集 n准确率\n",
    "    score = gscv.score(x_test, y_test)\n",
    "    print('score', score)\n",
    "    #     预测 predict 测试集\n",
    "    y_predict = gscv.predict(x_test)\n",
    "    print(y_predict == y_test)\n",
    "\n",
    "\n",
    "    print('交叉验证最好的结果：', gscv.best_score_)\n",
    "    print('最好的参数模型', gscv.best_estimator_)\n",
    "    print('每次交叉验证的准确率结果', gscv.cv_results_)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0  新闻分类  :使用朴素贝叶斯方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_20new_demo():\n",
    "    '''\n",
    "    新闻分类\n",
    "    使用朴素贝叶斯方法\n",
    "    :return: None\n",
    "    '''\n",
    "    # 获取数据集\n",
    "    news = fetch_20newsgroups(subset='all')\n",
    "\n",
    "    # 数据集合进行分割， 训练集合  测试集合\n",
    "    x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, train_size=0.8)\n",
    "\n",
    "    # 特征抽取 tfidf\n",
    "    tfidf = TfidfVectorizer()\n",
    "    x_train = tfidf.fit_transform(x_train)\n",
    "    x_test = tfidf.transform(x_test)\n",
    "\n",
    "    # 使用朴素贝叶斯进行 训练 评估 预测\n",
    "    mn = MultinomialNB(alpha=1)\n",
    "    mn.fit(x_train, y_train)\n",
    "\n",
    "    # 评估\n",
    "    score = mn.score(x_test, y_test)\n",
    "    print('score', score)\n",
    "\n",
    "    y_predict = mn.predict(x_test)\n",
    "\n",
    "    print(y_predict[0:100] == y_test[0:100])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 决策树预测泰坦尼克乘客生存状况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_demo():\n",
    "    '''\n",
    "    决策树预测泰坦尼克乘客生存状况\n",
    "    :return: None\n",
    "    '''\n",
    "    # 准备数据\n",
    "    titan = pd.read_csv('titanic.txt')\n",
    "    # 筛选特征值和目标值\n",
    "    x = titan[['pclass', 'age', 'sex']]\n",
    "    y = titan['survived']\n",
    "\n",
    "    # 处理年龄缺失值\n",
    "    x['age'].fillna(x['age'].mean(), inplace=True)\n",
    "    # print(x['age'])\n",
    "    # print(x['sex'])\n",
    "    # 针对性别（类别型特征） 需要 one_hot 编码\n",
    "    dict = DictVectorizer(sparse=False)\n",
    "    x = dict.fit_transform(x.to_dict(orient='records'))\n",
    "\n",
    "    # print(x)\n",
    "    # print(dict.get_feature_names())\n",
    "\n",
    "    # 数据集的划分\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "    # 使用决策树进行训练评估预测\n",
    "    dt = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "    dt.fit(x_train, y_train)\n",
    "\n",
    "    score = dt.score(x_test, y_test)\n",
    "\n",
    "    print('score', score)\n",
    "\n",
    "    # 把图结构保存成dot文件\n",
    "    export_graphviz(dt,out_file='./tree.dot')\n",
    "\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 随机森林预测泰坦尼克乘客生存状况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_random_forest_demo():\n",
    "    '''\n",
    "    随机森林预测泰坦尼克乘客生存状况\n",
    "    :return: None\n",
    "    '''\n",
    "    # 准备数据\n",
    "    titan = pd.read_csv('titanic.txt')\n",
    "    # 筛选特征值和目标值\n",
    "    x = titan[['pclass', 'age', 'sex']]\n",
    "    y = titan['survived']\n",
    "\n",
    "    # 处理年龄缺失值\n",
    "    x['age'].fillna(x['age'].mean(), inplace=True)\n",
    "    # print(x['age'])\n",
    "    # print(x['sex'])\n",
    "    # 针对性别（类别型特征） 需要 one_hot 编码\n",
    "    dict = DictVectorizer(sparse=False)\n",
    "    x = dict.fit_transform(x.to_dict(orient='records'))\n",
    "\n",
    "    # print(x)\n",
    "    # print(dict.get_feature_names())\n",
    "\n",
    "    # 数据集的划分\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "    # 使用随机森林进行训练评估预测\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # 构建参数字典\n",
    "    param_dict = {'n_estimators':[120, 200], 'max_depth':[5, 7, 10]}\n",
    "\n",
    "    # 交叉验证网格搜索\n",
    "    gscv = GridSearchCV(rf, param_grid=param_dict, cv=3)\n",
    "\n",
    "    gscv.fit(x_train, y_train)\n",
    "    score = gscv.score(x_test, y_test)\n",
    "    print('score', score)\n",
    "\n",
    "    print('最好的参数', gscv.best_estimator_)\n",
    "    print('验证集上最好表现', gscv.best_score_)\n",
    "    print('交叉验证的细节', gscv.cv_results_)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/pandas/core/generic.py:3660: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8022813688212928\n",
      "最好的参数 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "验证集上最好表现 0.8285714285714286\n",
      "交叉验证的细节 {'mean_fit_time': array([0.09314807, 0.14096085, 0.08615502, 0.15935858, 0.09676544,\n",
      "       0.15847731]), 'std_fit_time': array([7.01864519e-03, 5.15759597e-04, 2.12282430e-03, 1.64897065e-03,\n",
      "       4.54491659e-05, 3.11645515e-03]), 'mean_score_time': array([0.00913119, 0.01392754, 0.00882165, 0.01650143, 0.01011864,\n",
      "       0.01597436]), 'std_score_time': array([1.02105708e-04, 1.97986529e-04, 6.44772279e-05, 1.82994401e-04,\n",
      "       1.43648903e-04, 7.62610422e-04]), 'param_max_depth': masked_array(data=[5, 5, 7, 7, 10, 10],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[120, 200, 120, 200, 120, 200],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 5, 'n_estimators': 120}, {'max_depth': 5, 'n_estimators': 200}, {'max_depth': 7, 'n_estimators': 120}, {'max_depth': 7, 'n_estimators': 200}, {'max_depth': 10, 'n_estimators': 120}, {'max_depth': 10, 'n_estimators': 200}], 'split0_test_score': array([0.82571429, 0.82571429, 0.82571429, 0.82285714, 0.82      ,\n",
      "       0.81714286]), 'split1_test_score': array([0.81428571, 0.80857143, 0.8       , 0.80285714, 0.78857143,\n",
      "       0.78857143]), 'split2_test_score': array([0.84571429, 0.84571429, 0.82571429, 0.82285714, 0.83142857,\n",
      "       0.83142857]), 'mean_test_score': array([0.82857143, 0.82666667, 0.81714286, 0.81619048, 0.81333333,\n",
      "       0.81238095]), 'std_test_score': array([0.01298874, 0.01517845, 0.01212183, 0.00942809, 0.01812028,\n",
      "       0.01781742]), 'rank_test_score': array([1, 2, 3, 4, 5, 6], dtype=int32), 'split0_train_score': array([0.86      , 0.86      , 0.86285714, 0.86285714, 0.87285714,\n",
      "       0.87285714]), 'split1_train_score': array([0.86714286, 0.86285714, 0.87142857, 0.87142857, 0.87714286,\n",
      "       0.87714286]), 'split2_train_score': array([0.83714286, 0.83714286, 0.85142857, 0.85285714, 0.85714286,\n",
      "       0.85714286]), 'mean_train_score': array([0.8547619 , 0.85333333, 0.86190476, 0.86238095, 0.86904762,\n",
      "       0.86904762]), 'std_train_score': array([0.01279527, 0.01150766, 0.00819269, 0.00758923, 0.00859784,\n",
      "       0.00859784])}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    titanic_random_forest_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.9666666666666667\n",
      "[ True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "knn_iris_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.9666666666666667\n",
      "[ True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "交叉验证最好的结果： 0.95\n",
      "最好的参数模型 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "每次交叉验证的准确率结果 {'mean_fit_time': array([0.00052468, 0.00039593, 0.000542  , 0.00038298, 0.00036391,\n",
      "       0.00033816, 0.00035532]), 'std_fit_time': array([1.11315408e-04, 5.65413513e-05, 1.42318297e-04, 2.47537228e-05,\n",
      "       1.76551422e-05, 4.74580085e-06, 1.99858047e-05]), 'mean_score_time': array([0.00081094, 0.00096297, 0.00084805, 0.00084861, 0.00071605,\n",
      "       0.00073338, 0.00073703]), 'std_score_time': array([9.85316681e-05, 1.93125623e-04, 8.35370526e-05, 5.49544338e-05,\n",
      "       1.47875054e-05, 2.94373737e-05, 4.49511590e-05]), 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9, 11, 13],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}, {'n_neighbors': 9}, {'n_neighbors': 11}, {'n_neighbors': 13}], 'split0_test_score': array([0.97560976, 0.97560976, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]), 'split1_test_score': array([0.9  , 0.9  , 0.9  , 0.875, 0.825, 0.825, 0.825]), 'split2_test_score': array([0.92307692, 0.92307692, 0.94871795, 0.94871795, 0.94871795,\n",
      "       0.97435897, 0.97435897]), 'mean_test_score': array([0.93333333, 0.93333333, 0.95      , 0.94166667, 0.925     ,\n",
      "       0.93333333, 0.93333333]), 'std_test_score': array([0.03186248, 0.03186248, 0.04108569, 0.05157767, 0.07374303,\n",
      "       0.07731471, 0.07731471]), 'rank_test_score': array([3, 3, 1, 2, 7, 3, 3], dtype=int32), 'split0_train_score': array([1.        , 0.96202532, 0.94936709, 0.94936709, 0.96202532,\n",
      "       0.94936709, 0.96202532]), 'split1_train_score': array([1.    , 0.9625, 0.975 , 0.975 , 0.9625, 0.9625, 0.9375]), 'split2_train_score': array([1.        , 0.98765432, 0.96296296, 0.98765432, 0.98765432,\n",
      "       0.98765432, 0.98765432]), 'mean_train_score': array([1.        , 0.97072655, 0.96244335, 0.9706738 , 0.97072655,\n",
      "       0.96650714, 0.96239321]), 'std_train_score': array([0.        , 0.01197131, 0.01047104, 0.01592723, 0.01197131,\n",
      "       0.01588544, 0.02047707])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "knn_iris_gridsearch_cv_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8174904942965779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/pandas/core/generic.py:3660: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/jason/.virtualenvs/ai/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "titanic_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "fetch_20new_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
